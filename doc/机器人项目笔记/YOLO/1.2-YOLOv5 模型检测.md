# YOLOv5 模型检测

## 一、YOLOv5 模型版本选型

### 1. 模型家族版本差异

YOLOv5 提供 N、S、M、L、X 五个核心版本，结构框架一致，核心差异体现在参数量、推理速度与检测精度（MAP 指标），需根据硬件性能和业务需求选择：

|模型版本|参数量|推理速度|检测精度（MAP）|适用场景|
|---|---|---|---|---|
|YOLOv5N|1.9M（最小）|最快|最低|轻量设备、实时性优先场景（如边缘设备）|
|YOLOv5S|中等（倒数第二小）|较快|中等|平衡速度与精度，日常实操首选（前文环境验证默认模型）|
|YOLOv5M/L|递增|中等|中高|PC 端、对精度有一定要求的场景|
|YOLOv5X|最大|最慢|最高|高性能 GPU 设备、精度优先场景（如精密检测）|
### 2. 模型获取方式

- 自动下载：首次运行 `detect.py` 时，脚本会自动下载默认的 `yolov5s.pt` 模型（约 140M），保存至 YOLOv5 根目录。

- 手动下载：访问 YOLOv5 官方 GitHub 仓库 → 进入 Releases 页面 → 选择对应版本（如 V7.0）→ 下载所需模型文件（.pt 格式），手动放置到 YOLOv5 根目录（适合网络不佳时加速）。

## 二、detect.py 核心参数详解

通过命令行指定参数调用 `detect.py`，核心语法：`python detect.py --参数名 参数值`，以下为高频必用参数及实操演示。

### 1. --weights（指定模型文件）

作用：指定用于推理的预训练模型或自定义训练模型，是检测的核心参数。

#### 实操示例

```Bash

# 使用 YOLOv5S 模型推理（默认模型，可省略--weights参数）
python detect.py --weights yolov5s.pt

# 切换 YOLOv5X 模型推理（需提前下载 yolov5x.pt 至根目录）
python detect.py --weights yolov5x.pt
```

#### 效果对比

- YOLOv5S：推理 2 张测试图，耗时分别为 120.19ms、3ms，检测结果为 4 人 + 1 辆车。

- YOLOv5X：检测结果一致（精度略有提升），但推理时间显著增加，需权衡速度与精度选择。

### 2. --source（指定检测目标）

作用：定义检测对象的来源，支持多种输入类型，参数值根据目标类型灵活设置。

|参数值类型|示例|功能说明|
|---|---|---|
|数字（摄像头）|`--source 0`|调用电脑默认摄像头，进行实时视频检测|
|图片路径|`--source data/images/bus.jpg`|检测单张图片（示例为 YOLOv5 自带测试图）|
|视频路径|`--source test_video.mp4`|对本地视频文件逐帧检测|
|特殊值（屏幕）|`--source screen`|对整个电脑屏幕实时检测，按 `Ctrl+C` 终止程序|
#### 实操示例

```Bash

# 检测单张自带测试图
python detect.py --weights yolov5s.pt --source data/images/bus.jpg

# 对屏幕实时检测
python detect.py --weights yolov5s.pt --source screen
```

说明：检测结果默认保存至 `runs/detect/expX` 文件夹（X 为递增数字，区分多次检测结果）。

### 3. --conf-thres（置信度阈值）

作用：过滤低置信度检测框，仅显示置信度高于该阈值的目标，取值范围 0~1，默认值 0.25。

- 阈值越低：检测框越多，可能包含误检目标（置信度低的候选框被保留）。

- 阈值越高：检测框越少，仅保留高置信度目标，可能过滤掉真实低置信度目标。

#### 实操示例

```Bash

# 调高阈值至 0.8（仅保留高置信度目标）
python detect.py --weights yolov5s.pt --source data/images/bus.jpg --conf-thres 0.8

# 调低阈值至 0.05（保留更多候选框，易出现误检）
python detect.py --weights yolov5s.pt --source data/images/bus.jpg --conf-thres 0.05
```

#### 效果对比

- 阈值 0.8：仅检测到 1 个 person，领带等低置信度目标被过滤。

- 阈值 0.05：检测框数量激增，出现大量低置信度误检目标，干扰有效结果。

### 4. --iou-thres（IOU 阈值）

作用：基于非极大抑制（NMS）算法过滤重叠检测框，与置信度阈值逻辑相反，取值范围 0~1。

- 阈值越低：过滤越严格，重叠框越少（仅保留最优框）。

- 阈值越高：保留的重叠框越多，可保留同一目标的多个候选框。

说明：无需深入理解 NMS 原理，实操中可根据重叠框情况微调，默认值 0.45 适用于多数场景。

### 5. 其他常用参数

- `--img-size`：输入图像尺寸，默认 640（与 YOLOv5 预训练模型维度一致，建议不随意修改，避免影响精度）。

- `--max-det`：单张图片最大检测目标数量，默认值可满足日常需求，按需调整即可。

- `--device`：指定检测设备，不手动设置则自动匹配（优先 GPU，无 GPU 则用 CPU）。

- `--view-img`：检测过程中弹窗显示结果图片，便于实时查看。

- `--classes`：指定检测类别（如仅检测“人”），过滤无关类别，示例：`--classes 0`（0 对应 COCO 数据集的 person 类别）。

- `--no-save`：不保存检测结果，仅实时查看，适合调试场景。

## 三、基于 Torch Hub 的简化推理（轻量化封装）

前文 `detect.py` 代码量较大，封装或嵌入可视化界面时较繁琐，Torch Hub 提供极简方案，仅需几行代码即可完成检测，且支持加载本地模型。

### 1. 环境准备（安装 Jupyter Lab）

在激活的 yolov5 虚拟环境中执行安装命令：

```Bash

pip install jupyter lab
```

### 2. 新建 Notebook 文件

1. 启动 Jupyter Lab：命令行输入 `jupyter lab`，自动打开浏览器界面。

2. 新建文件：点击「New」→ 选择「Notebook（Python 3）」，命名为 `hub_detect.ipynb`。

### 3. 极简推理代码（支持本地模型）

```Python

# 1. 从 Torch Hub 加载模型（本地模型需指定 source='local'）
import torch
model = torch.hub.load('./', 'custom', path='yolov5s.pt', source='local')  # path 为本地模型路径

# 2. 指定检测目标（图片路径）
img = 'data/images/bus.jpg'  # 可替换为自定义图片路径

# 3. 模型推理
results = model(img)

# 4. 展示检测结果
results.show()
```

#### 代码说明

- 加载本地模型：需将 `path` 参数设为本地 .pt 模型文件路径，同时指定 `source='local'`。

- 结果输出：`results.show()` 弹窗显示检测结果，也可通过 `results.save()` 保存结果至本地。

- 优势：代码精简，易于封装和嵌入可视化界面，虽参数不如 `detect.py` 全面，但可满足多数检测需求。

## 四、检测实战注意事项

1. 模型与环境匹配：确保使用的模型版本与 YOLOv5 源码版本兼容（本文均基于 V7.0，避免高版本模型适配低版本源码）。

2. 硬件性能适配：YOLOv5X 等大模型需高性能 GPU 支持，否则推理速度极慢，低配置设备优先选 YOLOv5N/S。

3. 参数微调逻辑：优先调整 `--conf-thres` 优化检测精度，重叠框过多时微调`--iou-thres`。

4. 结果路径管理：多次检测后 `runs/detect/` 下会生成多个 exp 文件夹，建议按场景重命名，便于追溯结果。

5. 终止实时检测：调用摄像头或屏幕检测时，需在命令行按 `Ctrl+C` 终止程序，避免后台占用资源。